### PA-RCA Kafka Adapter
***
The PA-RCA kafka Adpater is a configurable plugin that can periodically stream the RCA outputs and push them to a specific Kafka queue. RCA data in the kafka queue will be read by consumers that can them redirect the decisions to a bounded slack bot. All RCA data are then stored in a local elasticsearch cluster via the kafka-elasticsearch sink connector.


### Design RFC
***
[RFC]()

### Prerequisite
***
  - [Apache Kafka](https://kafka.apache.org/)
  - [Elasticsearch Cluster](https://www.elastic.co/downloads/elasticsearch)
  - [Slack](https://slack.com/)


### Configuration, Setup and Run the plugin
***
To Run the plugin and read RCA data in a Slack channel sent by the Slack bot:
1. Start Zookeeper Service:
 Under kafka folder, run: `bin/zookeeper-server-start.sh config/zookeeper.properties`.

2. Start Kafka Server:
 Under kafka folder, run: `bin/kafka-server-start.sh config/server.properties`.

3. Create a [Slack bot](https://api.slack.com/messaging/webhooks) and copy the webhooks URL.

4. Copy the webhooks url and paste it in *kafka_adapter.conf*. Other settings including kafka bootstrap server, kafka topic, send and receive interval can also be configuerd in this file.

5. In kafka adpater folder, run `mvn package exec:java` to run the plugin.

The RCA data will then be returned from PA-RCA endpoint and then be sent to the configured kafka queue, the slack bot will then redirect the RCA data into the slack channel.

To consumer the RCA data in local elasticsearch cluster:

1. Setup local elasticsearch cluster.
2. Download [Kafka Elasticsearch Sink Connector](https://www.confluent.io/hub/confluentinc/kafka-connect-elasticsearch)
3. Copy all jar files of the sink connector to Kafka lib directory.

4. Add properties in `quickstart-elasticsearch.properties`, for example:
```
name=elasticsearch-sink
connector.class=io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
tasks.max=1
topics=logs
topic.index.map=logs:logs_index
connection.url=http://localhost:9200
type.name=log
key.ignore=true
schema.ignore=true
```

5. Configure Kafka connector properties file, for example: Add the following properties in `connect-standalone.properties`.

```
bootstrap.servers=localhost:9092
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false
offset.storage.file.filename=/tmp/connect.offsets
offset.flush.interval.ms=10000
```

6. Start Kafka Elasticsearch Sink Connector by running: `bin/connect-standalone.sh config/connect-standalone.properties config/quickstart-elasticsearch.properties`

7. After the plugin starts, the RCA data will be sent to local Elasticsearch Cluster. Users can query the RCA data via API request. 

For example: send the query request
```
 curl -XGET 'localhost:9200/rca_id/_search?pretty'
```

Will return:
```
{
  "took" : 158,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "rca_id",
        "_type" : "log",
        "_id" : "rca+0+1",
        "_score" : 1.0,
        "_source" : {
          "QueueRejectionClusterRca" : [
            {
              "rca_name" : "QueueRejectionClusterRca",
              "state" : "healthy",
              "timestamp" : 1596232812462
            }
          ],
          "ClusterTemperatureRca" : [
            { }
          ],
          "HotShardClusterRca" : [ ],
          "HotNodeClusterRca" : [
            {
              "rca_name" : "HotNodeClusterRca",
              "state" : "healthy",
              "timestamp" : 1596232812501
            }
          ],
          "HighHeapUsageClusterRca" : [
            {
              "rca_name" : "HighHeapUsageClusterRca",
              "state" : "healthy",
              "timestamp" : 1596232813118
          }
          ]
        }
      }
    ]
  }
}
```

### Current Limitations
***
- The plugin is seperated from the PA-RCA endpoint. All RCA data are generated by periodically hitting the PA-RCA endpoint.
- We don't cover 100% of unit tests and we will continue to add more test cases.

### Code of Conduct
***
This project has adopted an Open Source Code of Conduct.

### License
***
This library is licensed under the Apache 2.0 License.